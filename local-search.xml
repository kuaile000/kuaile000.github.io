<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>闲谈Redis脑裂</title>
    <link href="/2023/10/03/%E9%97%B2%E8%B0%88Redis%E8%84%91%E8%A3%82/"/>
    <url>/2023/10/03/%E9%97%B2%E8%B0%88Redis%E8%84%91%E8%A3%82/</url>
    
    <content type="html"><![CDATA[<h3 id="什么是脑裂"><a href="#什么是脑裂" class="headerlink" title="什么是脑裂"></a>什么是脑裂</h3><p>脑裂是在分布式系统中经常出现的问题之一，它指的是由于网络或节点故障等原因，导致一个分布式系统被分为多个独立的子系统，每个子系统独立运行，无法相互通信，同时认为自己是整个系统的主节点，这就会导致整个系统失去一致性和可用性。</p><h3 id="Redis脑裂原因、危害、解决"><a href="#Redis脑裂原因、危害、解决" class="headerlink" title="Redis脑裂原因、危害、解决"></a>Redis脑裂原因、危害、解决</h3><p>Redis的脑裂问题可能发生在网络分区或者主节点出现问题的时候：</p><ul><li>网络分区：网络故障或分区导致了不同子集之间的通信中断。<ul><li>Master节点，哨兵和Slave节点被分割为了两个网络，Master处在一个网络中，Slave库和哨兵在另外一个网络中，此时哨兵发现和Master连不上了，就会发起主从切换，选一个新的Master，这时候就会出现两个主节点的情况</li></ul></li><li>主节点问题：集群中的主节点之间出现问题，导致不同的子集认为它们是正常的主节点。<ul><li>Master节点有问题，哨兵就会开始选举新的主节点，但是在这个过程中，原来的那个Master节点又恢复了，这时候就可能会导致一部分Slave节点认为他是Master节点，而另一部分Slave新选出了一个Master</li></ul></li></ul><p>脑裂问题可能导致以下问题：</p><ul><li>数据不一致：不同子集之间可能对同一数据进行不同的写入，导致数据不一致。</li><li>重复写入：在脑裂解决后，不同子集可能尝试将相同的写入操作应用到主节点上，导致数据重复。</li><li>数据丢失：新选出来的Master会向所有的实例发送slave of命令，让所有实例重新进行全量同步，而全量同步首先就会将实例上的数据先清空，所以在主从同步期间在原来那个Master上执行的命令将会被清空。</li></ul><p>那么如何防止脑裂的发生呢？</p><ul><li>​min-slaves-to-write：主库能进行数据同步的最少从库数量；</li><li>min-slaves-max-lag：主从库间进行数据复制时，从库给主库发送 ACK 消息的最大延迟秒数。</li><li>假设我们将 min-slaves-to-write 设置为 1，把 min-slaves-max-lag 设置为 10s。如果Master节点因为某些原因挂了 12s，导致哨兵判断主库客观下线，开始进行主从切换。同时，因为原Master宕机了 12s，没有一个（min-slaves-to-write）从库能和原主库在 10s（ min-slaves-max-lag） 内进行数据复制，这样一来，就因为不满足配置要求，原Master也就再也无法接收客户端请求了。这样一来，主从切换完成后，也只有新主库能接收请求，这样就没有脑裂的发生了。</li><li>但是：<ul><li>假设我们将 min-slaves-to-write 设置为 1，把 min-slaves-max-lag 设置为 10s，并且down-after-milliseconds时间为8s，也就是说，如果8秒连不上主节点，哨兵就会进行主从切换。</li><li>但是，如果主从切换的过程需要5s时间的话，就会有问题。</li><li>Master节点宕机8s时，哨兵判断主节点客观下线，开始进行主从切换，但是这个过程一共需要5s。那如果主从切换过程中，主节点有恢复运行，即第9秒Master恢复了，而min-slaves-max-lag设置为10s那么主节点还是可写的。</li><li>那么就会导致9s~12s这期间如果有客户端写入原Master节点，那么这段时间的数据会等新的Master选出来之后，执行了slaveof之后导致丢失。</li><li>Redis脑裂可以采用min-slaves-to-write和min-slaves-max-lag合理配置尽量规避，但无法彻底解决</li></ul></li></ul><h3 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h3><p>Zookeeper集群中的脑裂出现的原因通常有以下2种情况：</p><ol><li><strong>网络分区</strong></li><li><strong>主节点宕机</strong></li><li>解决：本质就是通过原子广播的方式，只有得到大多数节点的支持才能成为master，而如果旧master恢复后由于没有大多数节点的支持依旧无法完成写操作</li></ol>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2023/10/03/hello-world/"/>
    <url>/2023/10/03/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>浅谈协程</title>
    <link href="/2023/09/26/%E6%B5%85%E8%B0%88%E5%8D%8F%E7%A8%8B/"/>
    <url>/2023/09/26/%E6%B5%85%E8%B0%88%E5%8D%8F%E7%A8%8B/</url>
    
    <content type="html"><![CDATA[<h3 id="什么是协程"><a href="#什么是协程" class="headerlink" title="什么是协程"></a>什么是协程</h3><p><strong>进程</strong>是系统进行资源分配和保护的基本单位，<strong>线程</strong>是处理器调度和分派的基本单位</p><ul><li>进程具有一个独立的执行环境。 进程是程序在计算机上的一次执行活动 。通常情况下，进程拥有一个完整的、私有的基本运行资源集合。特别地，每个进程都有自己的内存空间。</li><li>线程有时也被称为轻量级的进程。进程和线程都提供了一个执行环境，但创建一个新的线程比创建一个新的进程需要的资源要少。线程是在进程中存在的，每个进程最少有一个线程。线程又如下特点：<ol><li>线程共享进程的资源，包括内存和打开的文件。线程之间的通信不用进行系统调用，更节约时间</li><li>线程更轻量，线程实体包括程序，数据和TCB</li><li>线程是调度的基本单位</li></ol></li></ul><p><strong>协程</strong>，是英语翻译过来的（Coroutine），也叫纤程，是协作的程序。</p><ul><li>协程，不让OS通过竞争的方式决定调用哪些线程，而是由用户自己决定如何去执行逻辑。</li><li>它可以让我们用逻辑流的顺序去写控制流，而且还不会导致操作系统级的线程阻塞。因为协程是由应用程序决定的，所以任务切换的上下文也会交给了用户态来保存。</li><li>减少上下文切换导致的资源消耗</li></ul><h3 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h3><p><strong>线程的实现方式主要有三种：分别是使用内核线程实现、使用用户线程实现以及使用用户线程加轻量级进程混合实现。</strong></p><ul><li><p><strong>内核线程（Kernel-Level Thread,KLT）</strong></p><ul><li><strong>就是直接由操作系统内核（Kernel）支持的线程，这种线程由内核来完成线程切换，内核通过操纵调度器（Scheduler）对线程进行调度，并负责将线程的任务映射到各个处理器上，并向应用程序提供API接口来管理线程。</strong></li><li>由于是基于内核线程实现的，所以各种线程操作，如创建、析构及同步，都需要进行系统调用。而系统调用的代价相对较高，需要在用户态（User Mode）和内核态（Kernel Mode）中来回切换。其次，每个轻量级进程都需要有一个内核线程的支持，因此轻量级进程要消耗一定的内核资源（如内核线程的栈空间），因此一个系统支持轻量级进程的数量是有限的。</li></ul></li><li><p><strong>用户线程（Kernel-Level Thread,KLT）</strong></p><ul><li>用户空间建立线程库，通过运行时系统(Run-time System)来完成线程的管理，因为这种线程的实现是在用户空间的，所以操作系统的内核并不知道线程的存在，所以内核管理的还是进程，所以这种线程的切换不需要内核操作。</li><li>这种线程实现方式的优点是线程切换快，并且可以运行在任何操作系统之上，只需要实现线程库就行了。但是缺点也比较明显，就是所有线程的操作都需要用户程序自己处理，并且因为大多数系统调用都是阻塞的，所以一旦一个进程阻塞了，那么进程中的所有线程也会被阻塞。还有就是多处理器系统中如何将线程映射到其他处理器上也是一个比较大的问题。</li></ul></li><li><p>混合实现线程</p><ul><li><p>实现原理其实是JDK不再是每一个线程都一对一的对应一个操作系统的线程了，而是会将多个虚拟线程映射到少量操作系统线程中，通过有效的调度来避免那些上下文切换。</p></li><li><p>虚拟线程总是守护线程。setDaemon (false)方法不能将虚拟线程更改为非守护线程。所以，需要注意的是，当所有启动的非守护线程都终止时，JVM将终止。这意味着JVM不会等待虚拟线程完成后才退出。</p></li><li><p>其次，即使使用setPriority()方法，虚拟线程始终具有normal的优先级，且不能更改优先级。在虚拟线程上调用此方法没有效果。</p></li><li><pre><code class="java">Thread.Builder virtualBuilder = Thread.ofVirtual().name(&quot;虚拟线程&quot;);// 不建议和线程池一起使用，多此一举try (var executor = Executors.newVirtualThreadPerTaskExecutor()) &#123;    IntStream.range(0, 10000).forEach(i -&gt; &#123;        executor.submit(() -&gt; &#123;            Thread.sleep(Duration.ofSeconds(1));            return i;        &#125;);    &#125;);&#125;</code></pre></li></ul></li></ul>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>新时代与老年代对象相互引用怎么办</title>
    <link href="/2023/09/15/%E6%96%B0%E6%97%B6%E4%BB%A3%E4%B8%8E%E8%80%81%E5%B9%B4%E4%BB%A3%E5%AF%B9%E8%B1%A1%E7%9B%B8%E4%BA%92%E5%BC%95%E7%94%A8%E6%80%8E%E4%B9%88%E5%8A%9E/"/>
    <url>/2023/09/15/%E6%96%B0%E6%97%B6%E4%BB%A3%E4%B8%8E%E8%80%81%E5%B9%B4%E4%BB%A3%E5%AF%B9%E8%B1%A1%E7%9B%B8%E4%BA%92%E5%BC%95%E7%94%A8%E6%80%8E%E4%B9%88%E5%8A%9E/</url>
    
    <content type="html"><![CDATA[<h3 id="跨代引用"><a href="#跨代引用" class="headerlink" title="跨代引用"></a>跨代引用</h3><p>JVM的跨代引用问题是指在Java堆内存的不同代之间存在引用关系，导致对象在不同代之间的引用被称为跨代引用。比如：新生代到老年代的引用，老年代到新生代的引用等。</p><p>在进行一次MinorGC（YoungGC）的时候，会从GC Root出发，然后进行可达性分析，假如当前正在进行一次Young GC，如果他发现一个对象处于老年代，那么JVM就会中断这条路径。</p><p>那么这时候，JVM就会认为只有A和B是可达的，就会在接下来的Young GC中把E回收掉，但是其实E是有引用的，只不过他的引用在老年代，发生了跨代引用。</p><h3 id="解决方式"><a href="#解决方式" class="headerlink" title="解决方式"></a>解决方式</h3><ol><li>在做YoungGC的时候，GC Root出发后扫描到老年代对象后不中断，继续扫描和标记，把所有在年轻代的对象都标记上。</li><li>在YoungGC的实时，把老年代的所有对象也作为GC Root，进行可达性分析扫描。</li></ol><p>以上两种做法，其实成本都太高了，甚至第一种要比第二种成本还要高，因为他不仅要扫描，还需要不断地做标记。</p><p><strong>Remembered Set</strong></p><ul><li>Remembered Set 的主要作用是跟踪老年代对象与年轻代）对象之间的引用关系，以帮助识别老年代中存活对象。他的核心目标是减少全堆扫描的开销。老年代中的对象通常存活更长时间，因此为了回收年轻代，JVM需要知道哪些老年代对象引用了年轻代对象，以确保不会错误地回收正在被老年代引用的年轻代对象。</li><li>Remembered Set 记录了老年代对象指向年轻代对象的引用关系，此后当发生Minor GC时，垃圾回收器不需要扫描整个老年代来确定哪些对象存活。它只需扫描Remembered Set中的条目，从而减少了扫描的开销。</li><li>Remember Set中的对象也会被加入到GC Roots进行扫描</li></ul>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>闲谈看门狗机制</title>
    <link href="/2023/08/15/%E9%97%B2%E8%B0%88%E7%9C%8B%E9%97%A8%E7%8B%97%E6%9C%BA%E5%88%B6/"/>
    <url>/2023/08/15/%E9%97%B2%E8%B0%88%E7%9C%8B%E9%97%A8%E7%8B%97%E6%9C%BA%E5%88%B6/</url>
    
    <content type="html"><![CDATA[<h3 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h3><p>为了避免Redis实现的分布式锁超时，Redisson中引入了watch dog的机制，他可以帮助我们在Redisson实例被关闭前，不断的延长锁的有效期。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">protected</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">scheduleExpirationRenewal</span><span class="hljs-params">(<span class="hljs-type">long</span> threadId)</span> &#123;<br>    <span class="hljs-type">ExpirationEntry</span> <span class="hljs-variable">entry</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">ExpirationEntry</span>();<br>    <span class="hljs-type">ExpirationEntry</span> <span class="hljs-variable">oldEntry</span> <span class="hljs-operator">=</span> EXPIRATION_RENEWAL_MAP.putIfAbsent(getEntryName(), entry);<br>    <span class="hljs-keyword">if</span> (oldEntry != <span class="hljs-literal">null</span>) &#123;<br>        oldEntry.addThreadId(threadId);<br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>        entry.addThreadId(threadId);<br>        <span class="hljs-keyword">try</span> &#123;<br>            renewExpiration();<br>        &#125; <span class="hljs-keyword">finally</span> &#123;<br>            <span class="hljs-keyword">if</span> (Thread.currentThread().isInterrupted()) &#123;<br>                cancelExpirationRenewal(threadId);<br>            &#125;<br>        &#125;<br>    &#125;<br>&#125;<br><br><span class="hljs-comment">//定时任务执行续期</span><br><span class="hljs-keyword">private</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">renewExpiration</span><span class="hljs-params">()</span> &#123;<br>    <span class="hljs-type">ExpirationEntry</span> <span class="hljs-variable">ee</span> <span class="hljs-operator">=</span> EXPIRATION_RENEWAL_MAP.get(getEntryName());<br>    <span class="hljs-keyword">if</span> (ee == <span class="hljs-literal">null</span>) &#123;<br>        <span class="hljs-keyword">return</span>;<br>    &#125;<br>    <br>    <span class="hljs-type">Timeout</span> <span class="hljs-variable">task</span> <span class="hljs-operator">=</span> getServiceManager().newTimeout(<span class="hljs-keyword">new</span> <span class="hljs-title class_">TimerTask</span>() &#123;<br>        <span class="hljs-meta">@Override</span><br>        <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">run</span><span class="hljs-params">(Timeout timeout)</span> <span class="hljs-keyword">throws</span> Exception &#123;<br>            <span class="hljs-type">ExpirationEntry</span> <span class="hljs-variable">ent</span> <span class="hljs-operator">=</span> EXPIRATION_RENEWAL_MAP.get(getEntryName());<br>            <span class="hljs-keyword">if</span> (ent == <span class="hljs-literal">null</span>) &#123;<br>                <span class="hljs-keyword">return</span>;<br>            &#125;<br>            <span class="hljs-type">Long</span> <span class="hljs-variable">threadId</span> <span class="hljs-operator">=</span> ent.getFirstThreadId();<br>            <span class="hljs-keyword">if</span> (threadId == <span class="hljs-literal">null</span>) &#123;<br>                <span class="hljs-keyword">return</span>;<br>            &#125;<br>            <br>            CompletionStage&lt;Boolean&gt; future = renewExpirationAsync(threadId);<br>            future.whenComplete((res, e) -&gt; &#123;<br>                <span class="hljs-keyword">if</span> (e != <span class="hljs-literal">null</span>) &#123;<br>                    log.error(<span class="hljs-string">&quot;Can&#x27;t update lock &#123;&#125; expiration&quot;</span>, getRawName(), e);<br>                    EXPIRATION_RENEWAL_MAP.remove(getEntryName());<br>                    <span class="hljs-keyword">return</span>;<br>                &#125;<br>                <br>                <span class="hljs-keyword">if</span> (res) &#123;<br>                    <span class="hljs-comment">// reschedule itself</span><br>                    renewExpiration();<br>                &#125; <span class="hljs-keyword">else</span> &#123;<br>                    cancelExpirationRenewal(<span class="hljs-literal">null</span>);<br>                &#125;<br>            &#125;);<br>        &#125;<br>    &#125;, internalLockLeaseTime / <span class="hljs-number">3</span>, TimeUnit.MILLISECONDS);<br>    <br>    ee.setTimeout(task);<br>&#125;<br><br><br><span class="hljs-comment">//使用LUA脚本，进行续期</span><br><span class="hljs-keyword">protected</span> CompletionStage&lt;Boolean&gt; <span class="hljs-title function_">renewExpirationAsync</span><span class="hljs-params">(<span class="hljs-type">long</span> threadId)</span> &#123;<br>    <span class="hljs-keyword">return</span> evalWriteAsync(getRawName(), LongCodec.INSTANCE, RedisCommands.EVAL_BOOLEAN,<br>            <span class="hljs-string">&quot;if (redis.call(&#x27;hexists&#x27;, KEYS[1], ARGV[2]) == 1) then &quot;</span> +<br>                    <span class="hljs-string">&quot;redis.call(&#x27;pexpire&#x27;, KEYS[1], ARGV[1]); &quot;</span> +<br>                    <span class="hljs-string">&quot;return 1; &quot;</span> +<br>                    <span class="hljs-string">&quot;end; &quot;</span> +<br>                    <span class="hljs-string">&quot;return 0;&quot;</span>,<br>            Collections.singletonList(getRawName()),<br>            internalLockLeaseTime, getLockName(threadId));<br>&#125;<br></code></pre></td></tr></table></figure><ul><li>可以看到，上面的代码的主要逻辑就是用了一个TimerTask来实现了一个定时任务，设置了internalLockLeaseTime &#x2F; 3的时长进行一次锁续期。默认的超时时长是30s，那么他会每10s进行一次续期，通过LUA脚本进行续期，再续30s</li><li>续期也不是无脑续，他也是有条件的，从EXPIRATION_RENEWAL_MAP中尝试获取一个KV对，如果查不到，就不续期了。而这个东西，会在unlock的时候操作的（即使失败了），对他进行remove，所以一个锁如果被解了，那么就不会再继续续期了</li><li>当我们加锁时，如果指定了超时时间，那么是不会被续期的。</li><li>尝试开启续期的过程中，如果线程被中断了，那么就会取消续期动作了</li><li>Redisson的续期是基于Java中的定时任务的，并且操作都是基于JVM的，所以，当应用宕机、下线或者重启后，续期任务就没有了。这样也能在一定程度上避免机器挂了但是锁一直不释放导致的死锁问题。</li></ul>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>浅谈网络安全</title>
    <link href="/2023/08/03/%E6%B5%85%E8%B0%88%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/"/>
    <url>/2023/08/03/%E6%B5%85%E8%B0%88%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/</url>
    
    <content type="html"><![CDATA[<h3 id="常见攻击"><a href="#常见攻击" class="headerlink" title="常见攻击"></a>常见攻击</h3><p><strong>DoS</strong></p><ul><li>DoS（拒绝服务，Denial of Service）就是利用合理的服务请求来占用过多的服务资源，从而使合法用户无法得到服务的响应。这是早期非常基本的网络攻击方式。</li><li>利用合理的服务请求来占用过多的服务资源，从而使合法用户无法得到服务的响应的行为，就是DoS攻击。</li></ul><p><strong>DDoS</strong></p><ul><li>DDoS 攻击可以具体分成两种形式：带宽消耗型以及资源消耗型。它们都是透过大量合法或伪造的请求占用大量网络以及器材资源，以达到瘫痪网络以及系统的目的。</li><li>被攻击主机上有大量等待的TCP连接； 网络中充斥着大量的无用的数据包； 受害主机无法正常和外界通讯； 受害主机无法处理所有正常请求； 严重时会造成系统死机。 对于用户来说，在常见的现象就是网站无法访问。</li><li>分布式Dos</li></ul><p><strong>CSRF</strong></p><ul><li><strong>CSRF（Cross-site request forgery跨站请求伪造，也被称为“one click attack”或者session riding，通常缩写为CSRF或者XSRF，是一种对网站的恶意利用。</strong></li><li>攻击者盗用了你的身份，以你的名义发送恶意请求。CSRF能够做的事情包括：以你名义发送邮件，发消息，盗取你的账号，甚至于购买商品，虚拟货币转账……造成的问题包括：个人隐私泄露以及财产安全。</li><li>受害者必须依次完成两个步骤：<ol><li>登录受信任网站A，并在本地生成Cookie。</li><li>在不登出A的情况下，访问危险网站B。</li></ol></li><li>你不能保证你登录了一个网站后，不再打开一个tab页面并访问另外的网站。</li><li>你不能保证你关闭浏览器了后，你本地的Cookie立刻过期，你上次的会话已经结束。</li></ul><p><strong>XSS</strong></p><ul><li><strong>跨站脚本攻击(Cross Site Scripting)，恶意攻击者往Web页面里插入恶意html代码，当用户浏览该页之时，嵌入其中Web里面的html代码会被执行，从而达到恶意攻击用户的特殊目的。</strong></li><li>我们有一个a页面，a页面中有一个前台表单，表单内容接受用户输入的用户名和密码。然后我们在b页面中打印出用户在a页面中输入的内容。如果用户正常输入，那么当然没问题。但是如果用户输入的是一段css代码或者javascript代码会发生什么？比如用户输入**<script>alert("攻击你");</script>** 那么，在b页面中就会弹出对话框。这就是简单的xss攻击。</li><li>防止xss攻击： 预防xss攻击的方法很简单，就是要遵守一个原则：任何时候都不完全相信用户的输入，要对用户的输入进行过滤。</li></ul><p><strong>DNS污染</strong>是指当一个DNS服务器被恶意修改或替换，导致该服务器不再返回正确的DNS记录，而是返回错误的记录，从而将用户错误地导向到恶意站点。有些时候，DNS污染是官方行为，目的是不让普通用户访问某些固定的网站。</p><p><strong>DNS劫持</strong>是指当一个攻击者截获DNS请求，并代替正确的DNS服务器，提供不正确的DNS记录，从而将用户错误地导向到恶意站点。</p><p><strong>”撞库”</strong>是黑客通过收集互联网已泄露的用户和密码信息，生成对应的字典表，尝试批量登陆其他网站后，得到一系列可以登录的用户。</p><p>**”拖库”**本来是数据库领域的术语，指从数据库中导出数据。到了黑客攻击泛滥的今天，它被用来指网站遭到入侵后，黑客窃取其数据库。</p><p><strong>“洗库”</strong>，属于黑客入侵的一种，就是黑客入侵网站，通过技术手段将有价值的用户数据归纳分析，售卖变现。</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>看看什么是状态机</title>
    <link href="/2023/07/15/%E7%9C%8B%E7%9C%8B%E4%BB%80%E4%B9%88%E6%98%AF%E7%8A%B6%E6%80%81%E6%9C%BA/"/>
    <url>/2023/07/15/%E7%9C%8B%E7%9C%8B%E4%BB%80%E4%B9%88%E6%98%AF%E7%8A%B6%E6%80%81%E6%9C%BA/</url>
    
    <content type="html"><![CDATA[<h3 id="状态机"><a href="#状态机" class="headerlink" title="状态机"></a>状态机</h3><p>在我们日常开发中，我们提到的状态机基本都是有限状态机，用于解决状态相关的问题。有限状态机可以通过状态转换和事件触发来描述程序的行为和状态迁移。</p><p>一个状态机通常包含以下几个要素：</p><ol><li>状态（States）：代表系统可能处于的各种状态，例如 “已下单”、”已支付”、”已发货” 等。</li><li>事件（Events）：触发状态转换的事件，例如 “下单”、”支付”、”发货” 等。</li><li>转换（Transitions）：定义状态之间的转换规则，即在某个事件发生时，系统从一个状态转换到另一个状态的规则。</li><li>动作（Actions）：在状态转换发生时执行的操作或行为。</li></ol><p>状态机的实现，有很多种方式，可以用一些状态机的框架，如Spring StateMachine，也可以用状态模式，也可以自己封装一个工具类都行。</p><p>如果没有一个严格的状态机控制的话，我们是可以随便修改订单的状态的，我们可以在已下单状态直接推进到已发货状态，这显然是不对的。</p><p>而状态机就是来控制这个状态的流转的他的目的都是把状态、事件、转换以及动作封装在一起的，他把这些东西内聚在一起了。有了它，一个已下单状态的订单，只能通过支付事件来驱动，并且还会有一些其他的约束，比如支付金额&gt;0（转移条件）等，然后他的下一个状态只能是已支付这样的。</p><h3 id="Spring-StateMachine"><a href="#Spring-StateMachine" class="headerlink" title="Spring StateMachine"></a>Spring StateMachine</h3><p>Spring State Machine（简称 Spring SM）是 Spring Framework 的一个模块，它提供了一个用于构建有限状态机的框架。</p><ul><li><p>获取任务状态，创建状态机</p></li><li><pre><code class="java">@Componentpublic class WorkStateMachineFactory implements StateMachineFactory &#123;    @Resource    private WorkStateMachineHandler stateMachineHandler;    @Override    public UntypedStateMachine createStateMachine(Object initialStateId) &#123;        UntypedStateMachineBuilder stateMachineBuilder = StateMachineBuilderFactory.create(WorkStateMachine.class);        UntypedStateMachine stateMachine = stateMachineBuilder.newUntypedStateMachine(initialStateId, StateMachineConfiguration.create());        //  添加监听器，开始处理，异常处理，完成处理        stateMachine.addDeclarativeListener(stateMachineHandler);        return stateMachine;    &#125;&#125;//-----------------------------UntypedStateMachine workMachine =     workStateMachineFactory.createStateMachine(WorkStatusEnum.valueOf(workStatus));workMachine.fire(MachineEventUtils.getWorkEventByReportStatus(workToStatus), reportContext);//状态改变@States(&#123;        @State(name = WorkStateConstants.RUNNABLE, initialState = true),        @State(name = WorkStateConstants.RUNNING),        @State(name = WorkStateConstants.STOPPING),        @State(name = WorkStateConstants.UNKNOWN),        @State(name = WorkStateConstants.FAIL),        @State(name = WorkStateConstants.STOPPED),        @State(name = WorkStateConstants.FINISHED)&#125;)@Transitions(&#123;        @Transit(from = WorkStateConstants.RUNNABLE, to = WorkStateConstants.FAIL, on = WorkEventConstants.IGNORE_GROUP,callMethod = &quot;fromRunnableToFailByIgnoreGroup&quot;),        @Transit(from = WorkStateConstants.RUNNABLE, to = WorkStateConstants.RUNNING, on = WorkEventConstants.TAKE, callMethod = &quot;fromRunnableToRunningByTake&quot;),        @Transit(from = WorkStateConstants.RUNNING, to = WorkStateConstants.RUNNING, on = WorkEventConstants.REPORT_RUNNING, callMethod = &quot;fromRunningToRunningByReportRunning&quot;),&#125;)@StateMachineParameters(stateType = WorkStatusEnum.class, eventType = WorkEventEnum.class, contextType = WorkContext.class)@Slf4jpublic class WorkStateMachine extends AbstractUntypedStateMachine &#123;    @Resource    private IWorkService workService;    /**     * 运行-&gt;运行失败 上报失败     */    public void fromRunnableToFailByIgnoreGroup(WorkStatusEnum from, WorkStatusEnum to, WorkEventEnum event, WorkContext context) &#123;        workService.workIgnoreGroup(from,to,event,context);    &#125;&#125;</code></pre></li><li><p>tips：由于StateMachine实例不是由Spring容器创建，所以这个过程中无法通过注解方式开启事务(Spring没有机会去创建事务代理)，如果需要事务，必须采用编程式事务，在AbstractStateMachineEngine的fire函数中隐式的实现。</p></li></ul>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>如何实现定时任务以及延迟任务</title>
    <link href="/2023/07/10/%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1%E4%BB%A5%E5%8F%8A%E5%BB%B6%E8%BF%9F%E4%BB%BB%E5%8A%A1/"/>
    <url>/2023/07/10/%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1%E4%BB%A5%E5%8F%8A%E5%BB%B6%E8%BF%9F%E4%BB%BB%E5%8A%A1/</url>
    
    <content type="html"><![CDATA[<h3 id="定时任务多种实现"><a href="#定时任务多种实现" class="headerlink" title="定时任务多种实现"></a>定时任务多种实现</h3><p><strong>单点系统</strong></p><ol><li><strong>ScheduledExecutorService类</strong>： ScheduledExecutorService是Java SE5中新增的一个定时任务执行器，它可以比Timer更精准地执行任务，并支持多个任务并发执行。通过调用ScheduledExecutorService.schedule()或ScheduledExecutorService.scheduleAtFixedRate()方法来安排任务的执行时间。</li><li><strong>DelayQueue</strong>：DelayQueue是一个带有延迟时间的无界阻塞队列，它的元素必须实现Delayed接口。当从DelayQueue中取出一个元素时，如果其延迟时间还未到达，则会阻塞等待，直到延迟时间到达。因此，我们可以通过将任务封装成实现Delayed接口的元素，将其放入DelayQueue中，再使用一个线程不断地从DelayQueue中取出元素并执行任务，从而实现定时任务的调度。</li><li><strong>Timer类和TimerTask类</strong>： Timer类是Java SE5之前的一个定时器工具类，可用于执行定时任务。TimerTask类则表示一个可调度的任务，通常通过继承该类来实现自己的任务，然后使用Timer.schedule()方法来安排任务的执行时间</li></ol><p><strong>分布式</strong></p><ol><li><strong>xxl-job</strong>：xxl-job是一款分布式定时任务调度平台，可以实现各种类型的定时任务调度，如定时执行Java代码、调用HTTP接口、执行Shell脚本等。xxl-job采用分布式架构，支持集群部署，可以满足高并发、大数据量的任务调度需求。</li></ol><h3 id="延迟任务实现"><a href="#延迟任务实现" class="headerlink" title="延迟任务实现"></a>延迟任务实现</h3><ol><li><strong>被动关闭</strong><ul><li>例如：就是订单创建好了之后。我们系统上不做主动关单，什么时候用户来访问这个订单了，再去判断时间是不是超过了过期时间，如果过了时间那就进行关单操作，然后再提示用户。</li><li>如果用户一直不来查看这个订单，那么就会有很多脏数据冗余在数据库中一直无法被关单。</li></ul></li><li><strong>定时任务</strong><ul><li>分布式调度平台</li><li>对数据库造成压力。 定时任务集中扫表，这会使得数据库IO在短时间内被大量占用和消耗，如果没有做好隔离，并且业务量比较大的话，就可能会影响到线上的正常业务。</li><li>时间不精准。 一般定时任务基于固定的频率、按照时间定时执行的，那么就可能会发生很多订单已经到了超时时间，但是定时任务的调度时间还没到，那么就会导致这些订单的实际关闭时间要比应该关闭的时间晚一些。</li><li>无法处理大数据量。 定时任务的方式是会把本来比较分散的关闭时间集中到任务调度的那一段时间，如果订单量比较大的话，那么就可能导致任务执行时间很长，整个任务的时间越长，订单被扫描到时间可能就很晚，那么就会导致关闭时间更晚。</li><li>分库分表问题。</li></ul></li><li>DelayQueue<ul><li><strong>基于JDK的DelayQueue方案只适合在单机场景、并且数据量不大的场景中使用，如果涉及到分布式场景，那还是不建议使用。</strong></li><li>DelayQueue是基于JVM内存的，一旦机器重启了，里面的数据就都没有了。</li></ul></li><li>时间轮<ul><li>基于Netty的HashedWheelTimer可以帮助我们快速的实现一个时间轮，这种方式和DelayQueue类似，缺点都是基于内存、集群扩展麻烦、内存有限制等等。</li><li><strong>基于Netty的时间轮方案比基于JDK的DelayQueue效率更高，实现起来更简单，但是同样的，只适合在单机场景、并且数据量不大的场景中使用，如果涉及到分布式场景，那还是不建议使用。</strong></li></ul></li><li>kafka<ul><li>Kafka 中的时间轮的实现是 TimingWheel 类，位于 kafka.utils.timer 包中。基于Kafka的时间轮同样可以得到O(1)时间复杂度，性能上还是不错的。</li><li>通过时间轮记录任务到期时间，再配合DelayQueue进行时间推动</li><li>基于Kafka的时间轮的实现方式，在实现方式上有点复杂，需要依赖kafka，但是他的稳定性和性能都要更高一些，而且适合用在分布式场景中。</li></ul></li><li>RocketMQ延迟消息<ul><li>RocketMQ的延迟消息并不是支持任意时长的延迟的，它只支持：1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h这几个时长。（商业版支持任意时长）</li><li><strong>关单时长刚好和RocketMQ延迟消息支持的时长匹配的话，那么是可以基于RocketMQ延迟消息来实现的。否则，这种方式并不是最佳的。（但是在RocketMQ 5.0中新增了基于时间轮实现的定时消息，可以解决这个问题！）</strong></li></ul></li><li>RabbitMQ死信队列<ul><li>当RabbitMQ中的一条正常的消息，因为过了存活时间（TTL过期）、队列长度超限、被消费者拒绝等原因无法被消费时，就会变成Dead Message，即死信。</li><li>当一个消息变成死信之后，他就能被重新发送到死信队列中（其实是交换机-exchange）。</li><li>死信队列的实现方式存在一个问题，那就是可能造成队头阻塞，因为队列是先进先出的，而且每次只会判断队头的消息是否过期，那么，如果队头的消息时间很长，一直都不过期，那么就会阻塞整个队列，这时候即使排在他后面的消息过期了，那么也会被一直阻塞。</li></ul></li><li>RabbitMQ插件<ul><li>以往我们基于死信队列的方式，是消息先会投递到一个正常队列，在TTL过期后进入死信队列。但是基于插件的这种方式，消息并不会立即进入队列，而是先把他们保存在一个基于Erlang开发的Mnesia数据库中，然后通过一个定时器去查询需要被投递的消息，再把他们投递到x-delayed-message队列中。</li><li><strong>RabbitMQ插件的方式可以实现延迟消息，并且不存在消息阻塞的问题，但是因为是基于插件的，而这个插件支持的最大延长时间是(2^32)-1 毫秒，大约49天，超过这个时间就会被立即消费。</strong></li></ul></li><li>Redis过期监听<ul><li>这个方案不建议大家使用，是因为Redis官网上明确的说过，Redis并不保证Key在过期的时候就能被立即删除，更不保证这个消息能被立即发出。所以，消息延迟是必然存在的，随着数据量越大延迟越长，延迟个几分钟都是常事儿。</li></ul></li><li>Redis的ZSet<ul><li>zset是一个有序集合，每一个元素(member)都关联了一个 score，可以通过 score 排序来取集合中的值。</li><li><strong>使用redis zset来实现订单关闭的功能的优点是可以借助redis的持久化、高可用机制。避免数据丢失。但是这个方案也有缺点，那就是在高并发场景中，有可能有多个消费者同时获取到同一个订单号，一般采用加分布式锁解决，但是这样做也会降低吞吐型。</strong></li><li>在大多数业务场景下，如果幂等性做得好的，多个消费者取到相同数据也无妨</li></ul></li><li>Redisson<ul><li>Redisson中定义了分布式延迟队列RDelayedQueue，这是一种基于我们前面介绍过的zset结构实现的延时队列，它允许以指定的延迟时长将元素放到目标队列中。</li><li>其实就是在zset的基础上增加了一个基于内存的延迟队列。当我们要添加一个数据到延迟队列的时候，redisson会把数据+超时时间放到zset中，并且起一个延时任务，当任务到期的时候，再去zset中把数据取出来，返回给客户端使用。</li><li><strong>基于Redisson的实现方式，是可以解决基于zset方案中的并发重复问题的，而且还能实现方式也比较简单，稳定性、性能都比较高。</strong></li></ul></li></ol><h3 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h3><ul><li><p>定时任务可以定时执行的原理是通过操作系统提供的定时器实现的。定时器是计算机系统的一个重要组成部分，它可以周期性地发出信号或中断，以便操作系统或其他应用程序可以在指定的时间间隔内执行某些任务。</p></li><li><p>在定时任务中，操作系统或应用程序会利用计时器或定时器来定期检查当前时间是否达到了预定的执行时间，如果当前时间已经达到了预定的时间，系统会自动执行相应的任务或定时事件。在操作系统中，常见的定时任务管理工具有crontab（Linux系统）、Windows Task Scheduler（Windows系统）等。</p></li><li><p>总之，定时任务可以定时执行，是因为操作系统或应用程序利用定时器周期性地检查当前时间，一旦达到预定时间就会自动执行相应的任务。</p></li></ul>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>谈谈InnoDB四大特性</title>
    <link href="/2023/07/03/%E8%B0%88%E8%B0%88InnoDB%E5%9B%9B%E5%A4%A7%E7%89%B9%E6%80%A7/"/>
    <url>/2023/07/03/%E8%B0%88%E8%B0%88InnoDB%E5%9B%9B%E5%A4%A7%E7%89%B9%E6%80%A7/</url>
    
    <content type="html"><![CDATA[<h3 id="Change-Buffer"><a href="#Change-Buffer" class="headerlink" title="Change Buffer"></a>Change Buffer</h3><ul><li>旧版Insert Buffer，只对insert生效，而Change Buffer对CUD都生效</li><li>只对非唯一索引生效，在写过程中，先判断数据索引页是否在缓冲池中，如果不在则加入Change Buffer，按一定的频率进行合理地合并，再写回disk中，减少IO带来的性能损耗</li></ul><h3 id="Double-Write（页副本）"><a href="#Double-Write（页副本）" class="headerlink" title="Double Write（页副本）"></a>Double Write（页副本）</h3><ul><li>Doublewrite缓存是位于系统表空间的存储区域，用来缓存InnoDB的数据页从innodb buffer pool中flush之后并写入到数据文件之前，所以当操作系统或者数据库进程在数据页写磁盘的过程中崩溃，Innodb可以在doublewrite缓冲找到数据页的备份而用来执行crash恢复。</li><li>数据页写入doublewrite缓存的动作所需要的IO消耗要小于写入线文件的消耗，因为此写入操作会以一次大的连续块的方式写入。</li><li>在应用（apply）重做日志前，用户需要一个页的当写入失效发生时，先通过页的副本来还原该页，再进行做，这就是double write.（redo log无法恢复数据页损坏的问题，恢复必须是数据页正常并且redo log正常。）</li><li>因为存储引擎缓冲池内的数据页大小默认为16KB，而文件系统一页大小为4KB，所以在进行刷盘操作时，就有可能发生数据库准备刷新脏页时，需要四次IO才能将16KB的数据页刷入磁盘，但是数据库发生意外宕机，导致此时才刷了2个文件系统里的页，这种情况被称为写失效（partial page write），此时重启后，磁盘上就是不完整的数据页，就算使用redo log也是无法进行恢复的。</li><li>在对缓冲池的脏页进行刷新时，并不直接写磁盘，而是会通过memcpy函数将脏页先复制到内存中的Double write buffer</li><li>通过Double write buffer再分两次，每次1MB顺序地写入共享表空间的物理磁盘上，然后马上调用fsync函数，同步磁盘，避免缓冲写带来的问题</li></ul><h3 id="自适应Hash索引"><a href="#自适应Hash索引" class="headerlink" title="自适应Hash索引"></a>自适应Hash索引</h3><ul><li>针对二级索引</li><li>通过监控频繁查询的数据（连续3次），生成hash索引以此来加快数据的查询速度</li></ul><h3 id="预读"><a href="#预读" class="headerlink" title="预读"></a>预读</h3><ul><li>线性预读<ul><li>以extent为单位，将下一个顺序可能读到的数据提前读入缓存</li></ul></li><li>随机预读<ul><li>以page为单位，着眼于将当前extent中剩余的page提前读入缓存（Buffer Pool）</li></ul></li></ul>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>基于本地消息表实现最终一致性</title>
    <link href="/2023/07/02/%E5%9F%BA%E4%BA%8E%E6%9C%AC%E5%9C%B0%E6%B6%88%E6%81%AF%E8%A1%A8%E5%AE%9E%E7%8E%B0%E6%9C%80%E7%BB%88%E4%B8%80%E8%87%B4%E6%80%A7/"/>
    <url>/2023/07/02/%E5%9F%BA%E4%BA%8E%E6%9C%AC%E5%9C%B0%E6%B6%88%E6%81%AF%E8%A1%A8%E5%AE%9E%E7%8E%B0%E6%9C%80%E7%BB%88%E4%B8%80%E8%87%B4%E6%80%A7/</url>
    
    <content type="html"><![CDATA[<h3 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h3><ul><li><p>这个方案的主要思想是将分布式事务拆分为本地事务和消息事务两个部分，本地事务在本地数据库中进行提交或回滚，而消息事务则将消息写入消息中间件中，以实现消息的可靠投递和顺序性。</p></li><li><p>一般来说的做法是，在发送消息之前，先创建一条本地消息，并且保证写本地业务数据的操作和写本地消息记录的操作在同一个事务中。这样就能确保只要业务操作成功，本地消息一定可以写成功。</p></li><li><p>然后再基于本地消息，调用MQ发送远程消息。</p></li><li><p>消息发出去之后，等待消费者消费，在消费者端，接收到消息之后，做业务处理，处理成功后再修改本地消息表的状态。</p></li><li><p>这个过程中，可能有几个步骤都可能发生失败，那么如果失败了怎么办呢？</p><ul><li>1、2如果失败，因为在同一个事务中，所以事务会回滚，3及以后的步骤都不会执行。数据是一致的。</li><li>3如果失败，那么就需要有一个定时任务，不断的扫描本地消息数据，对于未成功的消息进行重新投递。</li><li>4、5如果失败，则依靠消息的重投机制，不断地重试。</li><li>6、7如果失败，那么就相当于两个分布式系统中的业务数据已经一致了，但是本地消息表的状态还是错的。这种情况也可以借助定时任务继续重投消息，让下游幂等消费再重新更改消息状态，或者本系统也可以通过定时任务去查询下游系统的状态，如果已经成功了，则直接推进消息状态即可。</li></ul></li></ul><p><img src="/2023/07/02/%E5%9F%BA%E4%BA%8E%E6%9C%AC%E5%9C%B0%E6%B6%88%E6%81%AF%E8%A1%A8%E5%AE%9E%E7%8E%B0%E6%9C%80%E7%BB%88%E4%B8%80%E8%87%B4%E6%80%A7/image-20231004154832916.png" alt="image-20231004154832916"></p><h3 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h3><p>优点：</p><ol><li>可靠性高：基于本地消息表实现分布式事务，可以将消息的发送和本地事务的执行进行原子性的提交，从而保证了消息的可靠性。</li><li>可扩展性好：基于本地消息表实现分布式事务，可以将消息的发送和本地事务的执行分开处理，从而提高了系统的可扩展性。</li><li>适用范围广：基于本地消息表实现分布式事务，可以适用于多种不同的业务场景，可以满足不同业务场景下的需求</li></ol><p>缺点：</p><ol><li>实现复杂度高：基于本地消息表实现分布式事务，需要设计复杂的事务协议和消息发送机制，并且需要进行相应的异常处理和补偿操作，因此实现复杂度较高。</li><li>系统性能受限：基于本地消息表实现分布式事务，需要将消息写入本地消息表，并且需要定时扫描本地消息表进行消息发送，因此对系统性能有一定影响。</li></ol>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>关于MESI的一些事</title>
    <link href="/2023/06/28/%E5%85%B3%E4%BA%8EMESI%E7%9A%84%E4%B8%80%E4%BA%9B%E4%BA%8B/"/>
    <url>/2023/06/28/%E5%85%B3%E4%BA%8EMESI%E7%9A%84%E4%B8%80%E4%BA%9B%E4%BA%8B/</url>
    
    <content type="html"><![CDATA[<h4 id="MESI：最终一致性"><a href="#MESI：最终一致性" class="headerlink" title="MESI：最终一致性"></a><strong>MESI</strong>：最终一致性</h4><ol><li>M（Modified）：代表该缓存行中的内容被修改了，并且该缓存行只被缓存在该CPU中。这个状态的缓存行中的数据和内存中的不一样，在未来的某个时刻它会被写入到内存中（当其他CPU要读取该缓存行的内容时。或者其他CPU要修改该缓存对应的内存中的内容时<ul><li>当我们要修改变量时，需要等待B-CPU将变量S变为I，也就是等待ACK响应，当A-CPU收到B响应时才能将变量进行修改</li><li>以此引入Store Buffer</li></ul></li><li>E（Exclusive）：代表该缓存行对应内存中的内容只被该CPU缓存，其他CPU没有缓存该缓存对应内存行中的内容。</li><li>S（Shared）：该状态意味着数据不止存在本地CPU缓存中，还存在别的CPU的缓存中。这个状态的数据和内存中的数据是一致的。</li><li>I（Invalid）：代表该缓存行中的内容是无效的</li></ol><h4 id="Store-Buffer"><a href="#Store-Buffer" class="headerlink" title="Store Buffer"></a>Store Buffer</h4><ul><li>有了Store Buffer，A-CPU便可以直接修改S变量，然后交给Store Buffer来等待ACK的响应，当收到确认后便可以将变量写入A-CPU本地缓存</li><li>但是，Store Buffer的存储大小是有限的，我们无法将大量变量都存进Store Buffer中等待ACK的确认，因此我们需要引入失效队列</li></ul><h4 id="失效队列"><a href="#失效队列" class="headerlink" title="失效队列"></a>失效队列</h4><ul><li>有了失效队列，Store Buffer中的变量便能够在失效消息被投入B中时，便可以收到ACK的确认，等到B-CPU空闲下来后便可以去消费失效队列中的消息</li></ul><h4 id="指令重排"><a href="#指令重排" class="headerlink" title="指令重排"></a>指令重排</h4><ul><li>我们所熟悉的指令重排便是由于这两个缓存导致的，比如我们对A、B进行修改，但是B先投入到失效队列中导致B变量先被放入本地缓存中，这也会导致可见性问题</li><li>读写屏障便是屏蔽这两个队列<ul><li>写屏障必须要我们在进行写操作前，将所有失效变量刷入失效队列中</li><li>读屏障则是要求CPU在读操作之前，将失效队列中的所有消息进行消费，之后再去读变量</li></ul></li></ul><h4 id="总线嗅探机制"><a href="#总线嗅探机制" class="headerlink" title="总线嗅探机制"></a><strong>总线嗅探机制</strong></h4><p>CPU和内存通过总线（BUS）互通消息。CPU感知其他CPU的行为（比如读、写某个缓存行）就是是通过嗅探（Snoop）线性中其他CPU发出的请求消息完成的，有时CPU也需要针对总线中的某些请求消息进行响应。这被称为”总线嗅探机制“。</p><p><strong>嗅探风暴</strong></p><p>当我们对一个变量或多个进行频繁修改时，便会不断的引发嗅探机制的触发，导致CPU总线资源消耗过高，这便是嗅探风暴</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>记SQL优化</title>
    <link href="/2023/06/28/%E8%AE%B0SQL%E4%BC%98%E5%8C%96/"/>
    <url>/2023/06/28/%E8%AE%B0SQL%E4%BC%98%E5%8C%96/</url>
    
    <content type="html"><![CDATA[<h3 id="起因"><a href="#起因" class="headerlink" title="起因"></a>起因</h3><p>线上查询接口响应迟缓，达到2s延迟以上，通过生产接口测试，接口响应延时达到5s以上。通过简单接口测试排查得出单表（任务执行表，包含任务执行状态，参数，关联字段）sql查询时间较长。</p><h3 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h3><ul><li>接口sql涉及表数据量过大（1000W-60多字段，包含temple等大字段）</li><li>打印sql，sql分析explain<ul><li>联合索引字段覆盖较少，导致扫描索引全表后仍进行大量回表查询操作</li><li>表数据量过多</li><li>order by未走索引</li><li>type：index</li><li>row：6多W</li><li>extra：using where，using filesort，using index</li></ul></li></ul><h3 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h3><ul><li>重新建立SQL索引</li><li>order by字段改为id，id为雪花算法（分布式id）</li><li>建立历史数据表<ul><li>建立history表</li><li>建立bak表</li><li>建立temp表</li><li>建立索引</li><li>temp表导入一个月的数据</li><li>temp与正式表相互改名</li><li>将正式表一个月以前逻辑删除数据导入history，将未删除数据导入bak表</li><li>bak表与temp表相互改名</li><li>将temp表增量数据导入bak表（基于大于bak主键id的数据或者基于if exist）</li></ul></li></ul>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>分布式锁常见实现</title>
    <link href="/2023/06/15/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%B8%B8%E8%A7%81%E5%AE%9E%E7%8E%B0/"/>
    <url>/2023/06/15/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%B8%B8%E8%A7%81%E5%AE%9E%E7%8E%B0/</url>
    
    <content type="html"><![CDATA[<h2 id="实现方式"><a href="#实现方式" class="headerlink" title="实现方式"></a>实现方式</h2><h3 id="数据库"><a href="#数据库" class="headerlink" title="数据库"></a>数据库</h3><h4 id="第一种"><a href="#第一种" class="headerlink" title="第一种"></a>第一种</h4><ul><li><p>当我们要锁住某个方法或资源时，我们就在该表中增加一条记录，想要释放锁的时候就删除这条记录。</p></li><li><pre><code class="sql">CREATE TABLE `methodLock` (  `id` int(11) NOT NULL AUTO_INCREMENT COMMENT &#39;主键&#39;,  `method_name` varchar(64) NOT NULL DEFAULT &#39;&#39; COMMENT &#39;锁定的方法名&#39;,  `desc` varchar(1024) NOT NULL DEFAULT &#39;备注信息&#39;,  `update_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT &#39;保存数据时间，自动生成&#39;,  PRIMARY KEY (`id`),  UNIQUE KEY `uidx_method_name` (`method_name `) USING BTREE) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT=&#39;锁定中的方法&#39;;<figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><code class="hljs csharp"><br>- 因为我们对method_name做了唯一性约束，这里如果有多个请求同时提交到数据库的话，数据库会保证只有一个操作可以成功，那么我们就可以认为操作成功的那个线程获得了该方法的锁，可以执行方法体内容。<br><br>- 问题：<br><br>  <span class="hljs-number">1.</span> 这把锁强依赖数据库的可用性，数据库是一个单点，一旦数据库挂掉，会导致业务系统不可用。<br>     - 主从<br>  <span class="hljs-number">2.</span> 这把锁没有失效时间，一旦解锁操作失败，就会导致锁记录一直在数据库中，其他线程无法再获得到锁。<br>     - 定时任务<br>  <span class="hljs-number">3.</span> 这把锁只能是非阻塞的，因为数据的insert操作，一旦插入失败就会直接报错。没有获得锁的线程并不会进入排队队列，要想再次获得锁就要再次触发获得锁操作。<br>     - 循环<br>  <span class="hljs-number">4.</span> 这把锁只能是非阻塞的，因为数据的insert操作，一旦插入失败就会直接报错。没有获得锁的线程并不会进入排队队列，要想再次获得锁就要再次触发获得锁操作。<br>     - 加字段，如线程ID等<br><br><span class="hljs-meta">#### 第二种</span><br><br>- 在查询语句后面增加<span class="hljs-keyword">for</span> update，数据库会在查询过程中给数据库表增加排他锁（这里再多提一句，InnoDB引擎在加锁的时候，只有通过索引进行检索的时候才会使用行级锁，否则会使用表级锁。<br>- 这里我们希望使用行级锁，就要给method_name添加索引，值得注意的是，这个索引一定要创建成唯一索引，否则会出现多个重载方法之间无法同时被访问的问题。重载方法的话建议把参数类型也加上。）。当某条记录被加上排他锁之后，其他线程无法再在该行记录上增加排他锁。<br>- 通过connection.commit()操作来释放锁。<br>- 天然阻塞<br>- 如果数据量少容易扫全表，使用表锁<br>- 长时间不提交，容易打满数据库连接<br><br><span class="hljs-meta">### Redis</span><br><br><span class="hljs-number">1.</span> Lua脚本<br><br><span class="hljs-number">2.</span> setnx<br><br>   - 实现简单：SETNX命令实现简单，易于理解和使用<br>   - 性能较高：由于SETNX命令的执行原子性，保证了分布式锁的正确性，而且在Redis中，SETNX命令是单线程执行的，所以性能较高。<br>   - 锁无法续期：如果加锁方在加锁后的执行时间较长，而锁的超时时间设置的较短，可能导致锁被误释放。<br>   - 无法避免死锁：如果加锁方在加锁后未能及时解锁（也未设置超时时间），且该客户端崩溃，可能导致死锁。<br>   - setnx不支持可重入，可以借助redission封装的能力实现可重入锁。<br><br><span class="hljs-number">3.</span> Redission<br><br>   - ```java<br>     @Service<br>     <span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title">LockTestService</span>&#123;<br>         @Autowired<br>         RedissonClient redisson;<br>         <br>         <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">testLock</span>()</span>&#123;<br>             RLock <span class="hljs-keyword">lock</span> = redisson.getLock(<span class="hljs-string">&quot;myLock&quot;</span>);<br>             <span class="hljs-keyword">try</span> &#123;<br>                 <span class="hljs-keyword">lock</span>.<span class="hljs-keyword">lock</span>(<span class="hljs-number">30</span>, TimeUnit.SECONDS);<br>                 <span class="hljs-comment">// 执行需要加锁的代码</span><br>             &#125; <span class="hljs-keyword">finally</span> &#123;<br>                 <span class="hljs-keyword">lock</span>.unlock();<br>             &#125;<br>         &#125;<br>     &#125;<br>     <br>     <span class="hljs-comment">//-----------------------------------------</span><br>     RLock fairLock = redisson.getFairLock(<span class="hljs-string">&quot;anyLock&quot;</span>);<br>     <span class="hljs-comment">//-----------------------------------------</span><br>     RLock lock1 = redissonInstance1.getLock(<span class="hljs-string">&quot;lock1&quot;</span>);<br>     RLock lock2 = redissonInstance2.getLock(<span class="hljs-string">&quot;lock2&quot;</span>);<br>     RLock lock3 = redissonInstance3.getLock(<span class="hljs-string">&quot;lock3&quot;</span>);<br>     <br>     RedissonMultiLock <span class="hljs-keyword">lock</span> = <span class="hljs-keyword">new</span> RedissonMultiLock(lock1, lock2, lock3);<br>     <span class="hljs-comment">// 同时加锁：lock1 lock2 lock3</span><br>     <span class="hljs-comment">// 所有的锁都上锁成功才算成功。</span><br>     <span class="hljs-keyword">lock</span>.<span class="hljs-keyword">lock</span>();<br>     ...<br>     <span class="hljs-keyword">lock</span>.unlock();<br>     <span class="hljs-comment">//-----------------------------------------</span><br>     RReadWriteLock rwlock = redisson.getReadWriteLock(<span class="hljs-string">&quot;anyRWLock&quot;</span>);<br>     <span class="hljs-comment">// 最常见的使用方法</span><br>     rwlock.readLock().<span class="hljs-keyword">lock</span>();<br>     <span class="hljs-comment">// 或</span><br>     rwlock.writeLock().<span class="hljs-keyword">lock</span>();<br></code></pre></td></tr></table></figure> - 可重入锁以外，Redisson还支持公平锁（FairLock）以及联锁（MultiLock）的使用。 - RedLock通过使用多个Redis节点，来提供一个更加健壮的分布式锁解决方案，能够在某些Redis节点故障的情况下，仍然能够保证分布式锁的可用性。 - 在进行加锁操作时，RedLock会向每个Redis节点发送相同的命令请求，每个节点都会去竞争锁，如果至少在大多数节点上成功获取了锁，那么就认为加锁成功。   - 网络分区：在网络分区的情况下，RedLock 仍然可以提供足够的可靠性。虽然会存在节点获取到相同锁的情况，但这种情况只会发生在网络分区发生时，且只会发生在一小部分节点上。而在网络分区恢复后，RedLock 会自动解锁。   - 时间漂移：RedLock 可以使用 NTP 等工具来同步不同机器之间的时间，从而避免时间漂移导致的问题。   - Redis 的主从复制：虽然 Redis 的主从复制可能导致锁的丢失，但这种情况非常罕见，并且可以通过多种方式来避免，例如使用 Redis Cluster。</code></pre></li></ul><h3 id="Zookeeper"><a href="#Zookeeper" class="headerlink" title="Zookeeper"></a>Zookeeper</h3><p>大致思想即为：每个客户端对某个方法加锁时，在zookeeper上的与该方法对应的指定节点的目录下，生成一个唯一的瞬时有序节点。 判断是否获取锁的方式很简单，只需要判断有序节点中序号最小的一个。 当释放锁的时候，只需将这个瞬时节点删除即可。同时，其可以避免服务宕机导致的锁无法释放，而产生的死锁问题。</p><p>来看下Zookeeper能不能解决以下问题。</p><ul><li>锁无法释放？使用Zookeeper可以有效的解决锁无法释放的问题，因为在创建锁的时候，客户端会在ZK中创建一个临时节点，一旦客户端获取到锁之后突然挂掉（Session连接断开），那么这个临时节点就会自动删除掉。其他客户端就可以再次获得锁。 </li><li>非阻塞锁？使用Zookeeper可以实现阻塞的锁，客户端可以通过在ZK中创建顺序节点，并且在节点上绑定监听器，一旦节点有变化，Zookeeper会通知客户端，客户端可以检查自己创建的节点是不是当前所有节点中序号最小的，如果是，那么自己就获取到锁，便可以执行业务逻辑了。 </li><li>不可重入？使用Zookeeper也可以有效的解决不可重入的问题，客户端在创建节点的时候，把当前客户端的主机信息和线程信息直接写入到节点中，下次想要获取锁的时候和当前最小的节点中的数据比对一下就可以了。如果和自己的信息一样，那么自己直接获取到锁，如果不一样就再创建一个临时的顺序节点，参与排队。 </li><li>单点问题？使用Zookeeper可以有效的解决单点问题，ZK是集群部署的，只要集群中有半数以上的机器存活，就可以对外提供服务。</li></ul><p>缺点：</p><ul><li>Zookeeper实现的分布式锁其实存在一个缺点，那就是性能上可能并没有缓存服务那么高。因为每次在创建锁和释放锁的过程中，都要动态创建、销毁瞬时节点来实现锁功能。ZK中创建和删除节点只能通过Leader服务器来执行，然后将数据同步到所有的Follower机器上。</li></ul>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>关于索引覆盖与索引下推</title>
    <link href="/2023/06/14/%E5%85%B3%E4%BA%8E%E7%B4%A2%E5%BC%95%E8%A6%86%E7%9B%96%E4%B8%8E%E7%B4%A2%E5%BC%95%E4%B8%8B%E6%8E%A8/"/>
    <url>/2023/06/14/%E5%85%B3%E4%BA%8E%E7%B4%A2%E5%BC%95%E8%A6%86%E7%9B%96%E4%B8%8E%E7%B4%A2%E5%BC%95%E4%B8%8B%E6%8E%A8/</url>
    
    <content type="html"><![CDATA[<h2 id="索引覆盖"><a href="#索引覆盖" class="headerlink" title="索引覆盖"></a>索引覆盖</h2><ul><li>覆盖索引（covering index）指一个查询语句的执行只用从索引中就能够取得，不必从数据表中读取。也可以称之为实现了索引覆盖。 </li><li>当一条查询语句符合覆盖索引条件时，MySQL只需要通过索引就可以返回查询所需要的数据，这样避免了查到索引后再返回表操作，减少I&#x2F;O提高效率。 </li><li>如，表covering_index_sample中有一个普通索引 idx_key1_key2(key1,key2)。<ul><li>当我们通过SQL语句：select key2 from covering_index_sample where key1 &#x3D; ‘keytest’;的时候，就可以通过覆盖索引查询，无需回表。</li><li>但是以下SQL，因为不符合最左前缀匹配，虽然是索引覆盖，但是也无法用到索引（会扫描索引树）：select key1 from covering_index_sample where key2 &#x3D; ‘keytest’;</li><li>但是如果SQL中查询的信息不包含在联合索引中，那么就不会走索引覆盖。如：select key2,key3 from covering_index_sample where key1 &#x3D; ‘keytest’；</li><li>例外：MySQL 8.0.13 版本中，对于range查询（什么是range后面会提到)，引入了索引跳跃扫描（Index Skip Scan）优化，支持不符合组合索引最左前缀原则条件下的SQL，依然能够使用组合索引，减少不必要的扫描。<ul><li>限制：<strong>这种查询优化比较适合于f1的取值范围比较少，区分度不高的情况，一旦f1的区分度特别高的话，这种查询可能会更慢。</strong>真正要不要走索引跳跃扫描，还是要经过MySQL的优化器进行成本预估之后做决定的。****</li><li>但是话又说回来了，我们一般不太会把区分度不高的字段放在联合索引的左边，不过事无绝对，既然MySQL给了一个优化的方案，就说明还是有这样的诉求的。</li></ul></li></ul></li></ul><h3 id="索引下推"><a href="#索引下推" class="headerlink" title="索引下推"></a>索引下推</h3><ul><li><p>索引下推是 MySQL 5.6引入了一种优化技术，默认开启，使用SET optimizer_switch &#x3D; ‘index_condition_pushdown&#x3D;off’;可以将其关闭。</p></li><li><p>官方文档中给的例子和解释如下： people表中（zipcode，lastname，firstname）构成一个索引<br>SELECT * FROM people WHERE zipcode&#x3D;’95054′ AND lastname LIKE ‘%etrunia%’ AND address LIKE ‘%Main Street%’;</p></li><li><p>如果没有使用索引下推技术，则MySQL会通过zipcode&#x3D;’95054’从存储引擎中查询对应的数据，返回到MySQL服务端，然后MySQL服务端基于lastname LIKE ‘%etrunia%’和address LIKE ‘%Main Street%’来判断数据是否符合条件。 </p></li><li><p>如果使用了索引下推技术，则MYSQL首先会返回符合zipcode&#x3D;’95054’的索引，然后根据lastname LIKE ‘%etrunia%’来判断索引是否符合条件。</p></li><li><p>如果符合条件，则根据该索引来定位对应的数据，如果不符合，则直接reject掉。 有了索引下推优化，可以在有like条件查询的情况下，减少回表次数。</p></li><li><p>当一条SQL使用到索引下推时，explain的执行计划中的extra字段中内容为：Using index condition</p></li><li><p>减少回表次数</p></li></ul>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Async注解有什么缺点</title>
    <link href="/2023/06/12/Async%E6%B3%A8%E8%A7%A3%E6%9C%89%E4%BB%80%E4%B9%88%E7%BC%BA%E7%82%B9/"/>
    <url>/2023/06/12/Async%E6%B3%A8%E8%A7%A3%E6%9C%89%E4%BB%80%E4%B9%88%E7%BC%BA%E7%82%B9/</url>
    
    <content type="html"><![CDATA[<h2 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h2><ul><li><p>@Async中关于线程池的使用部分在AsyncExecutionInterceptor中，在这个类中有一个getDefaultExecutor方法， 当我们没有做过自定义线程池的时候，就会用SimpleAsyncTaskExecutor这个线程池。</p></li><li><pre><code class="java">@Overrideprotected Executor getDefaultExecutor(BeanFactory beanFactory) &#123;    Executor defaultExecutor = super.getDefaultExecutor(beanFactory);    return (defaultExecutor != null ? defaultExecutor : new SimpleAsyncTaskExecutor());&#125;<figure class="highlight haxe"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs haxe"><br>- SimpleAsyncTaskExecutor这玩意坑很大，其实他并不是真的线程池，它是不会重用线程的，每次调用都会创建一个新的线程，也没有最大线程数设置。并发大的时候会产生严重的性能问题。<br><br>- 在没有Spring boot的加持下，异步任务使用了一个线程池，它的corePoolSize=<span class="hljs-number">8</span>, 阻塞队列采用了无界队列LinkedBlockingQueue。一旦采用了这样的组合，最大线程数就会形同虚设，因为超出<span class="hljs-number">8</span>个线程的任务，将全部会被放到无界队列里。<br><br>- 因此我们对于@Async注解的使用是极度容易造成OOM的，更何况我们对于自定义线程池都不敢说完全了解，就不要使用该注解啦。<br><br><span class="hljs-meta">## 如何解决</span><br><br>```java<br>@Configuration<br>@EnableAsync<br><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">AsyncExecutorConfig</span> </span>&#123;<br>    @Bean(<span class="hljs-string">&quot;registerSuccessExecutor&quot;</span>)<br>    <span class="hljs-keyword">public</span> Executor caseStartFinishExecutor() &#123;<br><br>        ThreadFactory namedThreadFactory = <span class="hljs-keyword">new</span> <span class="hljs-type">ThreadFactoryBuilder</span>()<br>                .setNameFormat(<span class="hljs-string">&quot;registerSuccessExecutor-%d&quot;</span>).build();<br><br>        ExecutorService executorService = <span class="hljs-keyword">new</span> <span class="hljs-type">ThreadPoolExecutor</span>(<span class="hljs-number">100</span>, <span class="hljs-number">200</span>,<br>                <span class="hljs-number">0</span>L, TimeUnit.MILLISECONDS,<br>                <span class="hljs-keyword">new</span> <span class="hljs-type">LinkedBlockingQueue</span>&lt;Runnable&gt;(<span class="hljs-number">1024</span>), namedThreadFactory, <span class="hljs-keyword">new</span> <span class="hljs-type">ThreadPoolExecutor</span>.AbortPolicy());<br><br>        <span class="hljs-keyword">return</span> executorService;<br>    &#125;<br><br>&#125;<br></code></pre></td></tr></table></figure></code></pre></li><li><p>我们通过@Async(“registerSuccessExecutor”)便可以将异步线程池指定为我们自定义的线程池，也就一定程度上的弥补该注解的问题。</p></li></ul><h2 id="扩展知识"><a href="#扩展知识" class="headerlink" title="扩展知识"></a>扩展知识</h2><h3 id="时间监听机制（观察者模式）"><a href="#时间监听机制（观察者模式）" class="headerlink" title="时间监听机制（观察者模式）"></a>时间监听机制（观察者模式）</h3><p>Spring Event是Spring框架中的一种事件机制，它允许不同组件之间通过事件的方式进行通信。Spring框架中的事件机制建立在观察者模式的基础上，允许应用程序中的组件注册监听器来监听特定类型的事件，并在事件发生时执行相应的操作。</p><p>Spring Event的使用需要定义以下三个内容：</p><ol><li>事件（Event）：事件是一个普通的Java对象，用于封装关于事件发生的信息。通常，事件类会包含一些数据字段，以便监听器能够获取事件的相关信息。</li><li>事件发布者（Event Publisher）：事件发布者是负责触发事件并通知所有注册的监听器的组件。</li><li>事件监听器（Event Listener）：事件监听器是负责响应特定类型事件的组件。它们实现了一个接口或者使用注解来标识自己是一个事件监听器，并定义了在事件发生时需要执行的逻辑。</li></ol><h3 id="如何实现"><a href="#如何实现" class="headerlink" title="如何实现"></a>如何实现</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">RegisterSuccessEvent</span> <span class="hljs-keyword">extends</span> <span class="hljs-title class_">ApplicationEvent</span> &#123;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-title function_">RegisterSuccessEvent</span><span class="hljs-params">(RegisterInfo registerInfo)</span> &#123;<br>        <span class="hljs-built_in">super</span>(registerInfo);<br>    &#125;<br>&#125;<br><span class="hljs-comment">// --------------------------------------------------------------</span><br><span class="hljs-meta">@Service</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">RegisterService</span>&#123;<br>  <span class="hljs-meta">@Autowired</span><br>  <span class="hljs-keyword">protected</span> ApplicationContext applicationContext;<br><br><span class="hljs-keyword">public</span> RegisterResponse <span class="hljs-title function_">register</span><span class="hljs-params">(RegisterInfo registerInfo)</span>&#123;<br><br><span class="hljs-comment">//用户注册核心代码</span><br><br>  <span class="hljs-comment">//发送一个注册完成的事件</span><br>    applicationContext.publishEvent(<span class="hljs-keyword">new</span> <span class="hljs-title class_">RegisterSuccessEvent</span>(registerInfo));<br><br>  &#125;<br>&#125;<br><span class="hljs-comment">// --------------------------------------------------------------</span><br><span class="hljs-meta">@Component</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">RegisterEventListener</span> &#123;<br><br>    <span class="hljs-meta">@EventListener(RegisterSuccessEvent.class)</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">onApplicationEvent</span><span class="hljs-params">(RegisterSuccessEvent event)</span> &#123;<br>        <span class="hljs-type">RegisterInfo</span> <span class="hljs-variable">registerInfo</span> <span class="hljs-operator">=</span> (RegisterInfo) event.getSource();<br>        <span class="hljs-comment">//注册完成逻辑</span><br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>默认情况下，Spring Event的调用时同步调用的。如果想要实现异步调用，也是支持的，最简单的方式就是借助@Async 注解对监听器进行标注，当然实际情况必然是不建议的，我们应当使用自定义线程池进行异步通知。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-meta">@Override</span><br>    <span class="hljs-keyword">public</span> &lt;T&gt; <span class="hljs-keyword">void</span> <span class="hljs-title function_">publish</span><span class="hljs-params">(String channel, T event)</span> &#123;<br>        List&lt;EventSubscriber&lt;T&gt;&gt; eventSubscribers =<br>                (List) <span class="hljs-built_in">this</span>.essProviders.entrySet()<br>                        .stream()<br>                        .filter((entry) -&gt; &#123;<br>                            <span class="hljs-keyword">return</span> ((SubscriptionKey) entry.getKey()).matches(channel, event);<br>                        &#125;)<br>                        .flatMap((entry) -&gt; &#123;<br>                            <span class="hljs-keyword">return</span> ((EssProvider) entry.getValue()).get().getEventSubscribers().stream();<br>                        &#125;)<br>                        .map((eventSubscriber) -&gt; &#123;<br>                            <span class="hljs-keyword">return</span> eventSubscriber;<br>                        &#125;)<br>                        .collect(Collectors.toList());<br>        <span class="hljs-built_in">this</span>.delivery.publishTo(eventSubscribers, event);<br>    &#125;<br><span class="hljs-comment">// --------------------------------------------------------------</span><br><span class="hljs-comment">// 我们可以通过Bean初始化机制对我们自定义的通知注解进行加载进CurrentHashMap中，当我们进行实践通知时便可以对不同的监听器进行通知</span><br></code></pre></td></tr></table></figure><h3 id="好处"><a href="#好处" class="headerlink" title="好处"></a>好处</h3><ol><li>代码解耦：通过使用事件机制，组件之间不需要直接互相依赖，从而减少了代码之间的耦合度。这使得代码更易于维护和扩展。</li><li>职责清晰：事件机制有助于将应用程序拆分为更小的模块，每个模块只关心要做的事儿，和关心自己需要监听的事件就行了。</li><li>异步处理：Spring Event机制支持异步事件处理，这意味着可以将事件的处理分发到不同的线程，提高了系统的响应性。</li><li>一对多：Spring Event是观察者模式的一种实现，他的一个事件可以有多个监听者，所以当我们有多个模块之间需要通信时，可以直接发一个事件出去，让监听者各自监听即可。</li></ol>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>浅谈接口幂等问题</title>
    <link href="/2023/05/30/%E6%B5%85%E8%B0%88%E6%8E%A5%E5%8F%A3%E5%B9%82%E7%AD%89%E9%97%AE%E9%A2%98/"/>
    <url>/2023/05/30/%E6%B5%85%E8%B0%88%E6%8E%A5%E5%8F%A3%E5%B9%82%E7%AD%89%E9%97%AE%E9%A2%98/</url>
    
    <content type="html"><![CDATA[<h3 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h3><ul><li>解决接口幂等问题，只需要记住一句口令”一锁、二判、三更新”，只要严格遵守这个过程，那么就可以解决并发问题。<ul><li>一锁：第一步，先加锁。可以加分布式锁、或者悲观锁都可以。但是一定要是一个互斥锁！</li><li>二判：第二步，进行幂等性判断。可以基于状态机、流水表、唯一性索引等等进行重复操作的判断。</li><li>三更新：第三步，进行数据的更新，将数据进行持久化。</li><li>三步需要严格控制顺序，确保加锁成功后进行数据查询和判断，幂等性判断通过后再更新，更新结束后释放锁。</li><li>以上操作需要有一个前提，那就是第一步加锁、和第二步判断的时候，需要有一个依据，这个就是幂等号了，通常需要和上游约定一个唯一ID作为幂等号。然后通过对幂等号加锁，再通过幂等号进行幂等判断即可。</li></ul></li><li>一锁这个过程，建议使用Redis实现分布式锁，因为他是非阻塞的高效率的互斥锁。非常适合在幂等控制场景中。</li><li>二判这个过程，如果有操作流水，建议基于操作流水做幂等，并将幂等号作为唯一性约束，确保唯一性。如果没有流水，那么基于状态机也是可以的。</li><li>但是不管怎么样，数据库的唯一性约束都要加好，这是系统的最后一道防线。万一前面的锁失效了，这里也能控制得住不会产生脏数据。</li><li>安全性欠佳做法<ul><li>唯一键</li><li>防重表（唯一性字段）</li><li>token防重</li><li>状态机</li><li>乐观锁（版本号）</li><li>（还可以）悲观锁（分布式锁&#x2F;for update + 判断是否符合条件 + 更新）（一锁二判三更新）</li></ul></li></ul><h3 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h3><ul><li><p>请求幂等：每次请求，如果参数一样，结果也要一样。</p></li><li><p>业务幂等：同一次业务请求，再拿到最终状态之后的每次请求，结果要保证一样。再没拿到最终状态之前，每一次请求需要正常执行业务逻辑，直到推进到最终状态。</p></li><li><p>比如，一次支付请求，如果支付返回处理中，或者系统异常等，我们需要重试，继续调用，直到他明确的返回支付成功，或者明确的无法成功的支付失败结果。</p></li></ul>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>HTTP版本发展</title>
    <link href="/2023/05/26/HTTP%E7%89%88%E6%9C%AC%E5%8F%91%E5%B1%95/"/>
    <url>/2023/05/26/HTTP%E7%89%88%E6%9C%AC%E5%8F%91%E5%B1%95/</url>
    
    <content type="html"><![CDATA[<h2 id="发展历程"><a href="#发展历程" class="headerlink" title="发展历程"></a>发展历程</h2><h3 id="HTTP是什么"><a href="#HTTP是什么" class="headerlink" title="HTTP是什么"></a>HTTP是什么</h3><ul><li><p>HTTP 是超文本传输协议，HTTP 不是互联网，也不是编程语言，是一种协议。HTTP 通常跑在 TCP&#x2F;IP 协议栈之上，依靠 IP 协议实现寻址和路由、TCP 协议实现可靠数据传输、DNS 协议实现域名查找、SSL&#x2F;TLS 协议实现安全通信。</p></li><li><p>HTTP 是一个用在计算机世界里的协议。它使用计算机能够理解的语言确立了一种计算机之间交流通信的规范，以及相关的各种控制和错误处理方式。</p></li><li><p>所谓 “<strong>「文本」</strong>”（Text），就表示 HTTP 传输的不是 TCP&#x2F;UDP 这些底层协议里被切分的杂乱无章的二进制包（datagram），而是完整的、有意义的数据，可以被浏览器、服务器这样的上层应用程序处理。</p></li></ul><h3 id="版本"><a href="#版本" class="headerlink" title="版本"></a>版本</h3><ol><li>HTTP&#x2F;1.0：短链接<ul><li>浏览器与服务器只保持短暂的连接，连接无法复用。也就是说每个TCP连接只能发送一个请求。发送数据完毕，连接就关闭，如果还要请求其他资源，就必须再新建一个连接。</li><li>TCP连接的建立需要三次握手，是很耗费时间的一个过程。所以，HTTP&#x2F;1.0版本的性能比较差。现在，随便打开一个网页，上面都会有很多图片、视频等资源，HTTP&#x2F;1.0显然无法满足性能要求。</li></ul></li><li>HTTP&#x2F;1.1：长链接，管道机制<ul><li>为了解决HTTP&#x2F;1.0存在的缺陷，HTTP&#x2F;1.1于1999年诞生。相比较于HTTP&#x2F;1.0来说，最主要的改进就是引入了持久连接。所谓的持久连接就是：在一个TCP连接上可以传送多个HTTP请求和响应，减少了建立和关闭连接的消耗和延迟。</li><li>管道机制，其中一个比较关键的就是服务端必须按照与请求相同的顺序回送HTTP响应。这也就意味着，如果一个响应返回发生了延迟，那么其后续的响应都会被延迟，直到队头的响应送达。这就是所谓的HTTP队头阻塞。</li><li><img src="/2023/05/26/HTTP%E7%89%88%E6%9C%AC%E5%8F%91%E5%B1%95/image-20231004131936279.png" alt="image-20231004131936279"></li></ul></li><li>HTTP&#x2F;2.0：报头压缩，二进制分帧，多路复用，全双工<ul><li>多路复用（multiplexing），多个请求共享一个tcp连接。在二进制分帧层中， HTTP&#x2F;2 会将所有传输的信息分割为更小的消息和帧（frame）,并对它们采用二进制格式的编码，这种单连接多资源的方式，减少了服务端的压力，使得内存占用更少，连接吞吐量更大。而且，TCP连接数的减少使得网络拥塞状况得以改善，同时慢启动时间的减少，使拥塞和丢包恢复速度更快。</li><li>header压缩，删除或者压缩HTTP头。HTTP&#x2F;1.1的header带有大量信息，而且每次都要重复发送。HTTP&#x2F;2 为了减少这部分开销，采用了HPACK 头部压缩算法对Header进行压缩。</li><li>Stream：HTTP2的请求的TCP的connection一旦建立，后续请求以stream的方式发送。每个stream的基本组成单位是frame（二进制帧）。客户端和服务器可以把 HTTP 消息分解为互不依赖的帧，然后乱序发送，最后再在另一端通过Stream ID把它们重新组合起来。<ul><li>流优先级：导致变化协议变卡，应该由应用层来定义</li><li>流依赖：一个资源必须依赖其他已经到达的资源</li></ul></li><li>服务端推送，HTTP&#x2F;1.1的header带有大量信息，而且每次都要重复发送。HTTP&#x2F;2 为了减少这部分开销，采用了HPACK 头部压缩算法对Header进行压缩。</li><li>对头阻塞问题：2.0只是解决了HTTP对头阻塞问题，并没有解决TCP对头阻塞问题，导致了不同的连接中TCP数据包之间会导致对头阻塞，并且在2.0中TCP对头阻塞影响会比在1.1中更加大。</li><li>HTTPS，如果使用的是安全的HTTPS协议，就还需要使用TLS协议进行安全数据传输，这个过程又要消耗一个RTT（TLS不同版本的握手机制不同，这里按照最小的消耗来算）</li><li>如何解决：升级TCP协议-&gt;协议僵化，放弃TCP</li></ul></li><li>HTTP&#x2F;3.0：QUIC协议，拥塞控制，连接迁移，协议竞速，0-RTT握手<ul><li>QUIC：基于UDP协议进行扩展</li><li>拥塞控制<ul><li>TCP重传包并不是递增的，导致其计算的RTT时间不准确，而QUIC是递增的</li><li><img src="/2023/05/26/HTTP%E7%89%88%E6%9C%AC%E5%8F%91%E5%B1%95/image-20231004133812543.png" alt="image-20231004133812543"></li></ul></li><li>流量控制<ul><li><img src="/2023/05/26/HTTP%E7%89%88%E6%9C%AC%E5%8F%91%E5%B1%95/image-20231004133609254.png" alt="image-20231004133609254"></li></ul></li><li>连接迁移<ul><li>通过id进行标识，而HTTP2.0之前通过四元组ip+端口号进行标识，可能负载均衡到不同的ip或进程</li><li>在迁移过程中不在通过四元组进行连接，而是通过Connection ID进行识别来快速确立连接。</li></ul></li><li>0-RTT握手<ul><li>通过握手期间携带Http数据，并且通过扩展字段来保留上次的加密密钥，具有安全性风险</li></ul></li><li>协议竞速<ul><li><img src="/2023/05/26/HTTP%E7%89%88%E6%9C%AC%E5%8F%91%E5%B1%95/image-20231004134056905.png" alt="image-20231004134056905"></li></ul></li></ul></li></ol><h2 id="扩展知识：多路复用"><a href="#扩展知识：多路复用" class="headerlink" title="扩展知识：多路复用"></a>扩展知识：多路复用</h2><ul><li><img src="/2023/05/26/HTTP%E7%89%88%E6%9C%AC%E5%8F%91%E5%B1%95/image-20231004134313801.png" alt="image-20231004134313801"></li><li>epoll：在epoll模式下，内核通过红黑树对文件描述符进行组织，便于我们对于CRUD，当有事件发生时便会出发就绪事件，将有事件的文件描述符拷贝到就绪队列中进行拷贝，降低了拷贝以及遍历导致的资源消耗，并且epoll多路复用兼具了两种不同的模式</li><li>ET<ul><li>边缘触发模式下，就绪时间只会在第一次发生时进行事件触发，即便一次没有处理完成也无法再次出发事件，以此在ET模式下，我们必须得使用非阻塞IO，防止任务饿死。</li></ul></li><li>LT<ul><li>在水平触发下，每次都将有就绪事件被触发。</li></ul></li><li>网络编程模型<ul><li>Reactor<ul><li><img src="/2023/05/26/HTTP%E7%89%88%E6%9C%AC%E5%8F%91%E5%B1%95/image-20231004135246853.png" alt="image-20231004135246853"></li><li><img src="/2023/05/26/HTTP%E7%89%88%E6%9C%AC%E5%8F%91%E5%B1%95/image-20231004135356258.png" alt="image-20231004135356258"></li><li><img src="/2023/05/26/HTTP%E7%89%88%E6%9C%AC%E5%8F%91%E5%B1%95/image-20231004135306783.png" alt="image-20231004135306783"></li><li><img src="/2023/05/26/HTTP%E7%89%88%E6%9C%AC%E5%8F%91%E5%B1%95/image-20231004135432313.png" alt="image-20231004135432313"></li></ul></li><li>Proactor<ul><li>前面提到的 Reactor 是非阻塞同步网络模式，而 Proactor 是异步网络模式。</li><li><img src="/2023/05/26/HTTP%E7%89%88%E6%9C%AC%E5%8F%91%E5%B1%95/image-20231004135532178.png" alt="image-20231004135532178"></li><li>Proactor Initiator 负责创建 Proactor 和 Handler 对象，并将 Proactor 和 Handler 都通过 Asynchronous Operation Processor 注册到内核；</li><li>Asynchronous Operation Processor 负责处理注册请求，并处理 I&#x2F;O 操作；</li><li>Asynchronous Operation Processor 完成 I&#x2F;O 操作后通知 Proactor；</li><li>Proactor 根据不同的事件类型回调不同的 Handler 进行业务处理；</li><li>Handler 完成业务处理；</li></ul></li><li><img src="/2023/05/26/HTTP%E7%89%88%E6%9C%AC%E5%8F%91%E5%B1%95/image-20231004135708020.png" alt="image-20231004135708020"></li></ul></li></ul>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>order by要如何使用</title>
    <link href="/2023/05/14/order-by%E8%A6%81%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8/"/>
    <url>/2023/05/14/order-by%E8%A6%81%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8/</url>
    
    <content type="html"><![CDATA[<h3 id="排序是怎么做的"><a href="#排序是怎么做的" class="headerlink" title="排序是怎么做的"></a>排序是怎么做的</h3><ul><li>order by 是做排序的，具体怎么排取决于优化器的选择，如果优化器认为走索引更快，那么就会用索引排序，否则，就会使用filesort (执行计划中extra中提示：using filesort），但是能走索引排序的情况并不多，并且确定性也没有那么强，很多时候，还是走的filesort。</li><li>filesort这种排序方式中，如果需要排序的内容比较少，就会基于内存中的sort_buffer，否则就需要使用磁盘临时文件进行排序了。并且在实际排序过程中，如果字段长度并不是特别长，那么就会使用全字段排序的方式直接在sort_buffer中排序后返回结果集。如果字段长度并特别长，那么就可能基于空间考虑，采用row_id排序，这样就会在排序后进行二次回表后返回结果集。</li></ul><h3 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h3><ul><li>当我们在做查询的时候，经常会使用order by进行排序，而当我们只想查询部分数量的时候，也会使用limit进行限制条数。</li><li>当我们在做查询的时候，经常会使用order by进行排序，而当我们只想查询部分数量的时候，也会使用limit进行限制条数。</li><li>这是由于<strong>如果ORDER BY的列中，多行具有相同的值，服务器可以自由地以任何顺序返回这些行，并且根据整体执行计划的不同可能会以不同的方式返回它们。</strong></li><li>所以，当我们在进行Limit+order by (字段), (ID)的时候，一定要尽量避免使用可能重复的字段，如时间、名称等，而应该选择唯一性的字段，如主键ID，或者唯一性索引。</li></ul>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>FirstBlog</title>
    <link href="/2023/05/03/FirstBlog/"/>
    <url>/2023/05/03/FirstBlog/</url>
    
    <content type="html"><![CDATA[<p><strong>记我很喜欢的一句话：</strong></p><p><strong>Everything will be ok in the end, if not ok, it is not in the end.</strong></p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
